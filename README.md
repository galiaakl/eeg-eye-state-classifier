# EEG Eye State Classifier with Advanced Preprocessing and Model Evaulation
## Overview
This project focuses on the implementation of an EEG signal processing pipeline that automatically detects the open and closed eye states of a person from their EEG recordings. The system merges the conventional approaches to processing signals with machine learning methods for high accuracy classification of the eye states.

## Project Pipeline:
### Signal Preprocessing
- **Notch Filtering:** Gets rid of 50/60 Hz power line noise.
- **Bandpass Filtering:** Extracts necessary EEG frequencies (1-45 Hz).
- **Independent Component Analysis (ICA)**: Disentangles neural signals from noise.
- **Component Classification:** Automagically distinguishes between artifact and neural components.

### Feature Extraction and Feature Selection
- Power spectral bands
- Some statistical moments
- Hjorth parameters
- A subset of features determined by multiple algorithms which is optimal.

### Model Comparison
- Five different classification algorithms.
- Cross-Validation: Performance assessment using stratified k-fold CV is more robust.
- Performance Metrics: Accuracy, AUC, sensitivity, specificity.

### Visualization
- **Component Analysis:** Time, frequency, and topographic domain plots.
- **Time and frequency analysis:** Wavelet based spectrograms.
- **Results of classification:** ROC curves, confusion matrices, and feature importance.
- **User Driven (interactive component):** Visual component suggestion system.

## Dataset
The pipeline is meant to process the EEG Eye State Dataset from UCI Machine Learning Repository.

### Dataset Specifications
- Format: .arff or .csv
- Channels: 14 EEG channels: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4
- Sample Rate: 128Hz
- Duration: Length of recording is continuous.
- Labels: Binarized into 0 and 1 (0 = eyes open, 1 = eyes closed).
- Size: Approximately 15,000 samples.

## Preprocessing
In this project, after applying typical filtering using a notch filter and a bandpass filter for EEG signal isolation, Independant Component Analysis (ICA) was used to extract the signal compoenents, and two different methods for decision on relevance were tested:
- Automatic removal of signal compoenents deemed less informative using a robust evaluation algorithm that relied on frequential content, regional concentration of that content, and similarity to signal with typical EEG eye state change signals.
- Manual selection of components to be removed given the plots generated by the visualiszation algorithm.
The second approach showed a 7% improvement in classification accuracy with significant improvements in specificity and recall, indicating superiority of this methos. This approach was implemented for the preparation of the dataset for the next steps.

## Feature Extraction
Two feature extraction approaches were tested:
- Statistical evaluation of all possibly relevant features (19 features per channel Ã— 14 channels = 266 features, notably
    'delta': power_in_delta_band,
    'theta': power_in_theta_band, 
    'alpha': power_in_alpha_band,
    'beta': power_in_beta_band,
    'gamma': power_in_gamma_band,
    'rel_delta': relative_delta_power,
    'rel_theta': relative_theta_power,
    'rel_alpha': relative_alpha_power,
    'rel_beta': relative_beta_power,
    'rel_gamma': relative_gamma_power,
    'alpha_beta_ratio': alpha/beta,
    'theta_beta_ratio': theta/beta,
    'alpha_theta_ratio': alpha/theta,
    'mean': mean_amplitude,
    'std': standard_deviation,
    'skew': skewness,
    'kurtosis': kurtosis,
    'mobility': hjorth_mobility,
    'complexity': hjorth_complexity)
  Feture selection methods used were:
  - ANOVA F-value
  - Mutual Information
  - Random Forest Importance

Selection through cross-validation
- Region-specific feature extraction:
  - extract per-channel key features (8 per channel):
    'alpha_power', 'beta_power', 'alpha_beta_ratio', 'rel_alpha', 'rel_beta',
    'mean', 'std', 'rms',
  - also extract regional features (9 total):
    'posterior_alpha_power',        
    'frontal_beta_power',          
    'global_alpha_beta_ratio',      
    'post_front_alpha_ratio',
    'front_post_beta_ratio',
  The first method was proven to be more computationally expensive while introducing no relevant improvements to the classification accuracy

The new sound approach and feature selection pipeline was found to be as follows:
- Extract 57 focused features (all based on domain knowledge -focus on occipital and frontal regions as they are more informative in eye state change detection)
- No statistical selection (every feature has a purpose)
- Train on all 57 features (all are relevant)

## Implemented Classification Algorithms
- **Logistic Regression**
  - Functionality: Linear baseline classifier
  - Strengths: Quick, straightforward, interpretable, and gives probabilistic outcomes
  - Hyperparameters: L2 regularization, max_iter=1000

- **Random Forest**
  - Functionality: Ensemble technique alongside importance of features
  - Strengths: Non-linearity, gives important feature ranking
  - Hyperparameters: 100 estimators, bootstrapped sampling

- **Gradient Boosting**
  - Functionality: Ensemble learning in sequence
  - Strengths: Accurate, good for complicated patterns
  - Hyperparameters: 100 estimators, optimized learning rate

- **Support Vector Machine**
- Functionality: Classification with maximum margin
- Strengths: Good performance in higher dimensions; utilizes the kernel trick
- Hyperparameters: RBF kernel with probability estimates on

- **Neural Network (MLP)**
  - Functionality: Deep learning technique
  - Strengths: Can approximate functions universally; identifies non-linear patterns
  - Hyperparameters: Hidden layers (100, 50), uses Adam optimizer

Results are reported in results/reports/classification-summary.txt
The test files will be preserved for later improvements. This repository is intended for sharing the optimized pipeline designed after rigirous tests and parameter evaluation.

## Acknowledgments
- UCI Machine Learning Repository for the EEG Eye State dataset
- scikit-learn developers for machine learning tools
- SciPy community for signal processing functions
- matplotlib team for visualization capabilities
